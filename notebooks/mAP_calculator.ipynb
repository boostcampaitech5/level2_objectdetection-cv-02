{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4SViyRMYpE8W",
    "outputId": "9d357c91-208e-48ef-ac39-2502d8378adb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install map_boxes==1.0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8HwFZgNpHlW",
    "outputId": "9f2e5161-084e-496f-d9b7-a7a934f74e18",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import fast version of function compute_overlap, will use slow one. Check cython intallation\n"
     ]
    }
   ],
   "source": [
    "from map_boxes import mean_average_precision_for_boxes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "azIZ5tNtNgPA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submissonchange(submissonpath:str, mode:str):\n",
    "    if mode != \"gt\":\n",
    "        df = pd.read_csv(submissonpath)\n",
    "        new = []\n",
    "        for img_id in range(4871):\n",
    "            try:\n",
    "                n = len(df['PredictionString'].values.tolist()[img_id].split())\n",
    "                for i in range(0, n, 6):\n",
    "                    xx = [f\"test/{img_id:04}.jpg\"] + df['PredictionString'].values.tolist()[img_id].split()[i:i+6]\n",
    "                    new.append(xx)\n",
    "            except:\n",
    "                new.append([f\"test/{img_id:04}.jpg\"]+[0, 0, 0, 0, 0, 0])\n",
    "    else:\n",
    "        df = pd.read_csv(submissonpath)\n",
    "        new = []\n",
    "        for img_id in range(4871):\n",
    "            try:\n",
    "                n = len(df['PredictionString'].values.tolist()[img_id].split())\n",
    "                for i in range(0, n, 6):\n",
    "                    xx = [f\"test/{img_id:04}.jpg\"] + df['PredictionString'].values.tolist()[img_id].split()[i:i+6]\n",
    "                    xx.pop(2)\n",
    "                    new.append(xx)\n",
    "            except:\n",
    "                new.append([f\"test/{img_id:04}.jpg\"]+[0, 0, 0, 0, 0])\n",
    "\n",
    "    return new\n",
    "\n",
    "gt = submissonchange(\"/opt/ml/baseline/mmdetection/work_dirs/best67.csv\", \"gt\") #64\n",
    "#new_pred = submissonchange(\"./ensemble_csv/sy_dh_2.csv\", \"new\")\n",
    "new_pred1 = submissonchange(\"/opt/ml/baseline/mmdetection/work_dirs/dir/paa_5787.csv\", \"0.57\")\n",
    "# new_pred2 = submissonchang?e(\"/opt/ml/baseline/mmdetection/work_dirs/dh_swinL_pseudo5_retina/retina_epoch_13.csv\", \"retina\")\n",
    "# new_pred3 = submissonchange(\"/opt/ml/baseline/mmdetection/work_dirs/dir/1/nms.csv\", \"nms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ava_GCPHOd1a",
    "outputId": "faf1bf3c-5538-46a8-c794-2ca24361454a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 4871\n",
      "Number of files in predictions: 4871\n",
      "Unique classes: 10\n",
      "Detections length: 4871\n",
      "Annotations length: 4871\n",
      "0                              | 0.006977 |  139236\n",
      "1                              | 0.012202 |  105158\n",
      "2                              | 0.007186 |   20497\n",
      "3                              | 0.003589 |   38468\n",
      "4                              | 0.006714 |   24381\n",
      "5                              | 0.007298 |   72570\n",
      "6                              | 0.005889 |   32420\n",
      "7                              | 0.009757 |   92478\n",
      "8                              | 0.002792 |    8266\n",
      "9                              | 0.002747 |   21280\n",
      "mAP: 0.006515\n",
      "-----------\\원본(호찬님 0.60짜리) 0.006515050692653253\n"
     ]
    }
   ],
   "source": [
    "mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred1, iou_threshold=0.5)\n",
    "\n",
    "print(\"-----------\\원본(호찬님 0.60짜리)\",mean_ap)\n",
    "# mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred2, iou_threshold=0.5)\n",
    "\n",
    "# print(\"-----------\\앙상블 결과\",mean_ap)\n",
    "# # mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred3, iou_threshold=0.5)\n",
    "\n",
    "# print(\"-----------\\nnms\",mean_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6vIZT0Utgm_"
   },
   "source": [
    "- mAP 0.4573 와 비교시( 사진 미인식 시  class 0 으로 부여한 경우 )\n",
    "> 리더보드 점수 > 0.4573과 제출할 submission 비교했을 때 점수\n",
    "\n",
    "    - mAP 0.2541 > *0.013374*\n",
    "    - mAP 0.3235 > *0.015914*\n",
    "    - mAP 0.4143 > *0.020560*\n",
    "    - mAP 0.4149 > *0.021096*\n",
    "    - mAP 0.4495 > *0.033456*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De0FPK1ErMiY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
